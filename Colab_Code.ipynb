{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:00:21.473394Z",
     "iopub.status.busy": "2025-06-04T00:00:21.472992Z",
     "iopub.status.idle": "2025-06-04T00:01:34.143657Z",
     "shell.execute_reply": "2025-06-04T00:01:34.142863Z",
     "shell.execute_reply.started": "2025-06-04T00:00:21.473367Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
      "Collecting flask-ngrok\n",
      "  Downloading flask_ngrok-0.0.25-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.2.9-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
      "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
      "Collecting packaging>=20.0 (from transformers)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n",
      "Downloading pyngrok-7.2.9-py3-none-any.whl (25 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyngrok, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, flask-ngrok\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.10.19\n",
      "    Uninstalling nvidia-curand-cu12-10.3.10.19:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n",
      "    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n",
      "    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "cesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "bigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\n",
      "pandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed flask-ngrok-0.0.25 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-24.2 pyngrok-7.2.9\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers langchain flask flask-ngrok pyngrok accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T00:01:36.412579Z",
     "iopub.status.busy": "2025-06-04T00:01:36.411967Z",
     "iopub.status.idle": "2025-06-04T00:01:36.845431Z",
     "shell.execute_reply": "2025-06-04T00:01:36.844486Z",
     "shell.execute_reply.started": "2025-06-04T00:01:36.412548Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9300911cc87f43ad80e32d86bff84485",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-04T03:48:12.989376Z",
     "iopub.status.busy": "2025-06-04T03:48:12.988305Z",
     "iopub.status.idle": "2025-06-04T03:55:35.396293Z",
     "shell.execute_reply": "2025-06-04T03:55:35.395396Z",
     "shell.execute_reply.started": "2025-06-04T03:48:12.989331Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "from flask import Flask, request, jsonify\n",
    "from pyngrok import ngrok\n",
    "import json\n",
    "import re\n",
    "import threading\n",
    "import time\n",
    "\n",
    "class CoLabLLMService:\n",
    "    def __init__(self):\n",
    "        self.model_name = \"mistralai/Mistral-Nemo-Instruct-2407\"\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        print(\"Loading LLM model...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name, \n",
    "            torch_dtype=torch.float16, \n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        print(\"LLM model loaded successfully!\")\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "    \n",
    "    def generate_text(self, prompt, max_length=1200, num_return_sequences=1):\n",
    "        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", truncation=True, max_length=2048)\n",
    "        inputs = inputs.to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                inputs,\n",
    "                max_length=max_length,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.pad_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id,\n",
    "                no_repeat_ngram_size=3\n",
    "            )\n",
    "        \n",
    "        responses = []\n",
    "        for output in outputs:\n",
    "            response = self.tokenizer.decode(output, skip_special_tokens=True)\n",
    "            response = response[len(self.tokenizer.decode(inputs[0], skip_special_tokens=True)):].strip()\n",
    "            responses.append(response)\n",
    "        \n",
    "        return responses\n",
    "    \n",
    "    def extract_json_block(self, text):\n",
    "        json_pattern = r'\\{.*?\\}'\n",
    "        matches = re.findall(json_pattern, text, re.DOTALL)\n",
    "        \n",
    "        if matches:\n",
    "            for match in matches:\n",
    "                try:\n",
    "                    json.loads(match)\n",
    "                    return match\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        json_code_pattern = r'```json\\s*(.*?)\\s*```'\n",
    "        code_matches = re.findall(json_code_pattern, text, re.DOTALL)\n",
    "        \n",
    "        if code_matches:\n",
    "            for match in code_matches:\n",
    "                try:\n",
    "                    json.loads(match)\n",
    "                    return match\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        \n",
    "        return '{\"recommendations\": [\"Unable to generate valid recommendations\"], \"reasoning\": \"LLM response parsing failed\"}'\n",
    "    \n",
    "    def get_recommendations(self, user_preferences, mobile_database, num_recommendations=2):\n",
    "        recommendation_schema = ResponseSchema(\n",
    "            name=\"recommendations\",\n",
    "            description=\"List of exactly 2 mobile phone recommendations from the provided database\"\n",
    "        )\n",
    "        \n",
    "        reasoning_schema = ResponseSchema(\n",
    "            name=\"reasoning\",\n",
    "            description=\"Detailed explanation of why these specific phones were recommended\"\n",
    "        )\n",
    "        \n",
    "        response_schemas = [recommendation_schema, reasoning_schema]\n",
    "        output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "        format_instructions = output_parser.get_format_instructions()\n",
    "        \n",
    "        recommendation_template = \"\"\"\n",
    "You are an expert mobile phone consultant with deep knowledge of smartphone specifications and user needs.\n",
    "\n",
    "User Requirements:\n",
    "- Price Range: {price_range}\n",
    "- RAM: {ram}GB minimum\n",
    "- Storage: {storage}GB minimum  \n",
    "- Camera: {camera_mp}MP minimum\n",
    "- Battery: {battery_mah}mAh minimum\n",
    "- Screen Size: Around {screen_size} inches\n",
    "- Operating System: {operating_system}\n",
    "- Processor Type: {processor_type}\n",
    "- Network: {network_type}\n",
    "\n",
    "Available Mobile Phones Database:\n",
    "{mobile_database}\n",
    "\n",
    "Based on the user's specific requirements and the available mobile phone database, recommend exactly 2 mobile phones that best match their needs. \n",
    "\n",
    "Your recommendations MUST be selected from the provided database only. Use the exact brand and model names as they appear in the database.\n",
    "\n",
    "Consider the following factors in your recommendation:\n",
    "1. How well each phone matches the user's specified requirements\n",
    "2. Value for money in the given price range\n",
    "3. Overall performance and user experience\n",
    "4. Brand reliability and build quality\n",
    "5. Future-proofing with latest features\n",
    "\n",
    "For the recommendations field, provide a list with exactly 2 items. Each item should be the exact \"Brand Model\" as it appears in the database.\n",
    "\n",
    "For the reasoning field, provide detailed explanation of why each recommended phone is suitable for this user.\n",
    "\n",
    "Respond ONLY in the structured JSON format as specified below:\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(\n",
    "            template=recommendation_template, \n",
    "            input_variables=[\"price_range\", \"ram\", \"storage\", \"camera_mp\", \"battery_mah\", \n",
    "                           \"screen_size\", \"operating_system\", \"processor_type\", \"network_type\", \n",
    "                           \"mobile_database\", \"format_instructions\"]\n",
    "        )\n",
    "        \n",
    "        messages = prompt.format(\n",
    "            price_range=user_preferences['price_range'],\n",
    "            ram=user_preferences['ram'],\n",
    "            storage=user_preferences['storage'],\n",
    "            camera_mp=user_preferences['camera_mp'],\n",
    "            battery_mah=user_preferences['battery_mah'],\n",
    "            screen_size=user_preferences['screen_size'],\n",
    "            operating_system=user_preferences['operating_system'],\n",
    "            processor_type=user_preferences['processor_type'],\n",
    "            network_type=user_preferences['network_type'],\n",
    "            mobile_database=mobile_database,\n",
    "            format_instructions=format_instructions\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            response = self.generate_text(messages, max_length=3000, num_return_sequences=1)\n",
    "            final_response = self.extract_json_block(response[0])\n",
    "            output_dict = output_parser.parse(final_response)\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'recommendations': output_dict.get('recommendations', []),\n",
    "                'reasoning': output_dict.get('reasoning', \"No reasoning provided\"),\n",
    "                'raw_response': response[0]\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': str(e),\n",
    "                'recommendations': [],\n",
    "                'reasoning': f\"Error generating recommendations: {str(e)}\"\n",
    "            }\n",
    "\n",
    "print(\"Initializing LLM service...\")\n",
    "llm_service = CoLabLLMService()\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health_check():\n",
    "    return jsonify({\"status\": \"healthy\", \"model_loaded\": True})\n",
    "\n",
    "@app.route('/recommend', methods=['POST'])\n",
    "def recommend():\n",
    "    try:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"NEW RECOMMENDATION REQUEST RECEIVED\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        data = request.json\n",
    "        user_preferences = data['user_preferences']\n",
    "        mobile_database = data['mobile_database']\n",
    "        num_recommendations = data.get('num_recommendations', 2)\n",
    "        \n",
    "        newline_char = '\\n'\n",
    "        db_entries = len(mobile_database.split(newline_char))\n",
    "        \n",
    "        print(\"Request Details:\")\n",
    "        print(f\"   • Requested recommendations: {num_recommendations}\")\n",
    "        print(f\"   • Database entries: {db_entries} phones\")\n",
    "        \n",
    "        result = llm_service.get_recommendations(\n",
    "            user_preferences, \n",
    "            mobile_database, \n",
    "            num_recommendations\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            print(result)\n",
    "            print(\"REQUEST COMPLETED SUCCESSFULLY\")\n",
    "            print(\"Sending response to local application...\")\n",
    "        else:\n",
    "            print(\"REQUEST FAILED\")\n",
    "            print(f\"   Error: {result.get('error', 'Unknown error')}\")\n",
    "        \n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        \n",
    "        return jsonify(result)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"FLASK ROUTE ERROR: {str(e)}\")\n",
    "        print(\"=\"*60 + \"\\n\")\n",
    "        return jsonify({\n",
    "            'success': False,\n",
    "            'error': str(e),\n",
    "            'recommendations': [],\n",
    "            'reasoning': f\"Service error: {str(e)}\"\n",
    "        }), 500\n",
    "\n",
    "def start_ngrok():\n",
    "    ngrok.set_auth_token(\"2y15p3PeuSTqFt5dacRBYGc_5GKwTdBkq\")\n",
    "    public_url = ngrok.connect(5000)\n",
    "    print(f\"Public URL: {public_url}\")\n",
    "    print(\"Copy this URL to use in your local application!\")\n",
    "    return public_url\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"STARTING LLM SERVICE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    ngrok_thread = threading.Thread(target=start_ngrok)\n",
    "    ngrok_thread.daemon = True\n",
    "    ngrok_thread.start()\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    print(\"LLM SERVICE IS READY!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Available endpoints:\")\n",
    "    print(\"   • GET  /health    - Check service status\")\n",
    "    print(\"   • POST /recommend - Get mobile recommendations\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"MONITORING MODE: All requests will be logged below\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    app.run(host='0.0.0.0', port=5000, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
